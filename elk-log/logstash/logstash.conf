input {
  kafka{ 
	bootstrap_servers => ["IP1:9092,IP2:9092"]
	group_id => "ifc_log"
	auto_offset_reset => "earliest"  
	topics => ["gateway-log-topic-dev"]
	codec=> multiline {
	    charset => "UTF-8"
		pattern => "(?<ServiceName>([a-zA-Z0-9-]*)):(?<InstanceName>([a-zA-Z0-9-]*)):(?<InstanceNameNum>([a-zA-Z0-9-]*))\s\[(?<traceId>([a-zA-Z0-9-]*))\,(?<spanId>([a-zA-Z0-9-]*))\,(?<isTraced>([a-zA-Z0-9-]*))\]"
		negate => true
		what => "previous"
		max_bytes => "10MiB"
        max_lines => 500
	}
	
  }
}

filter {
  grok { 
    match => ["message", "(?<ServiceName>([a-zA-Z0-9-]*)):(?<InstanceName>([a-zA-Z0-9-]*)):(?<InstanceNameNum>([a-zA-Z0-9-]*))\s\[(?<traceId>([a-zA-Z0-9-]*))\,(?<spanId>([a-zA-Z0-9-]*))\,(?<isTraced>([a-zA-Z0-9-]*))\]\s*%{TIMESTAMP_ISO8601:DateTime}\s*%{LOGLEVEL:Level}\s*(?<info>([\s\S]*))"]
  }
  mutate { replace => { message => "%{[info]}" } } 
  mutate { remove_field => ["tags","beat","offset","input_type","info","prospector","fields","@version"] }
  date {
    match => ["logdate", "yyyy-MM-dd HH:mm:ss"]
    target => "@timestamp"
  }
}



output {
  elasticsearch {
    hosts => ["ip1:9200","ip2:9200"]
    index => "gateway_log_dev-%{+YYYY.MM.dd}"      #索引名称
	document_type => "ebox_log"
	codec=> plain {
	    charset => "UTF-8"
	}
  }
}